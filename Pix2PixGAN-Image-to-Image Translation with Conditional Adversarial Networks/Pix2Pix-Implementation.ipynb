{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"Pix2Pix-Implementation.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"}},"cells":[{"cell_type":"code","metadata":{"colab_type":"code","executionInfo":{"status":"ok","timestamp":1582690392960,"user_tz":-300,"elapsed":26172,"user":{"displayName":"ZEESHAN NISAR","photoUrl":"","userId":"05353617243036990298"}},"id":"xa5ED42g3rJB","outputId":"634f9898-ff74-4bc4-b7c4-144970a84a91","colab":{"base_uri":"https://localhost:8080/","height":122}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","executionInfo":{"status":"ok","timestamp":1582690421071,"user_tz":-300,"elapsed":3375,"user":{"displayName":"ZEESHAN NISAR","photoUrl":"","userId":"05353617243036990298"}},"id":"oW_oa4hz5V97","outputId":"c0cc49eb-1a64-4dd1-ce4c-f13cc5534004","colab":{"base_uri":"https://localhost:8080/","height":80}},"source":["import tensorflow as tf\n","tf.VERSION"],"execution_count":2,"outputs":[{"output_type":"display_data","data":{"text/html":["<p style=\"color: red;\">\n","The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n","We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n","or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n","<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"execute_result","data":{"text/plain":["'1.15.0'"]},"metadata":{"tags":[]},"execution_count":2}]},{"cell_type":"code","metadata":{"colab_type":"code","executionInfo":{"status":"ok","timestamp":1582691756563,"user_tz":-300,"elapsed":3397,"user":{"displayName":"ZEESHAN NISAR","photoUrl":"","userId":"05353617243036990298"}},"id":"Ozns3f1d6VVi","outputId":"a456cfe0-dc87-4d54-f775-6b6812550911","colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["from keras.models import *\n","from keras.layers import *\n","from keras.optimizers import *\n","from keras.layers.advanced_activations import LeakyReLU\n","from keras.layers.convolutional import UpSampling2D, Conv2D\n","from keras_contrib.layers.normalization.instancenormalization import InstanceNormalization\n","import sys\n","import numpy as np\n","import os\n","\n","# Input shape\n","img_rows = 256\n","img_cols = 256\n","channels = 3\n","img_shape = (img_rows, img_cols, channels)\n","\n","# Calculate output shape of D (PatchGAN)\n","patch = int(img_rows / 2**4)\n","disc_patch = (patch, patch, 1)\n","\n","#Optimizer\n","optimizer = Adam(0.0002, 0.5)\n","\n","def Generator():\n","  \"\"\"Generator foloows U-Net Architecture\"\"\"\n","\n","  # Image input\n","  inputs = Input(shape=img_shape)\n","\n","  # Downsampling\n","  conv1 = Conv2D(filters=64, kernel_size=4, strides=2, padding='same')(inputs)\n","  conv1 = LeakyReLU(alpha=0.2)(conv1)\n","\n","  conv2 = Conv2D(filters=128, kernel_size=4, strides=2, padding='same')(conv1)\n","  conv2 = LeakyReLU(alpha=0.2)(conv2)\n","  conv2 = BatchNormalization(momentum=0.8)(conv2)\n","\n","  conv3 = Conv2D(filters=256, kernel_size=4, strides=2, padding='same')(conv2)\n","  conv3 = LeakyReLU(alpha=0.2)(conv3)\n","  conv3 = BatchNormalization(momentum=0.8)(conv3)\n","\n","  conv4 = Conv2D(filters=512, kernel_size=4, strides=2, padding='same')(conv3)\n","  conv4 = LeakyReLU(alpha=0.2)(conv4)\n","  conv4 = BatchNormalization(momentum=0.8)(conv4)\n","\n","  conv5 = Conv2D(filters=512, kernel_size=4, strides=2, padding='same')(conv4)\n","  conv5 = LeakyReLU(alpha=0.2)(conv5)\n","  conv5 = BatchNormalization(momentum=0.8)(conv5)\n","\n","  conv6 = Conv2D(filters=512, kernel_size=4, strides=2, padding='same')(conv5)\n","  conv6 = LeakyReLU(alpha=0.2)(conv6)\n","  conv6 = BatchNormalization(momentum=0.8)(conv6)\n","\n","  conv7 = Conv2D(filters=512, kernel_size=4, strides=2, padding='same')(conv6)\n","  conv7 = LeakyReLU(alpha=0.2)(conv7)\n","  conv7 = BatchNormalization(momentum=0.8)(conv7)\n","  \n","  # Upsampling\n","  deconv1 = UpSampling2D(size=2)(conv7)\n","  deconv1 = Conv2D(filters=512, kernel_size=4, strides=1, padding='same', activation='relu')(deconv1)\n","  deconv1 = BatchNormalization(momentum=0.8)(deconv1)\n","  deconv1 = Concatenate()([deconv1, conv6])\n","\n","  deconv2 = UpSampling2D(size=2)(deconv1)\n","  deconv2 = Conv2D(filters=512, kernel_size=4, strides=1, padding='same', activation='relu')(deconv2)\n","  deconv2 = BatchNormalization(momentum=0.8)(deconv2)\n","  deconv2 = Concatenate()([deconv2, conv5])\n","\n","  deconv3 = UpSampling2D(size=2)(deconv2)\n","  deconv3 = Conv2D(filters=512, kernel_size=4, strides=1, padding='same', activation='relu')(deconv3)\n","  deconv3 = BatchNormalization(momentum=0.8)(deconv3)\n","  deconv3 = Concatenate()([deconv3, conv4])\n","\n","  deconv4 = UpSampling2D(size=2)(deconv3)\n","  deconv4 = Conv2D(filters=256, kernel_size=4, strides=1, padding='same', activation='relu')(deconv4)\n","  deconv4 = BatchNormalization(momentum=0.8)(deconv4)\n","  deconv4 = Concatenate()([deconv4, conv3])\n","\n","  deconv5 = UpSampling2D(size=2)(deconv4)\n","  deconv5 = Conv2D(filters=128, kernel_size=4, strides=1, padding='same', activation='relu')(deconv5)\n","  deconv5 = BatchNormalization(momentum=0.8)(deconv5)\n","  deconv5 = Concatenate()([deconv5, conv2])\n","\n","  deconv6 = UpSampling2D(size=2)(deconv5)\n","  deconv6 = Conv2D(filters=64, kernel_size=4, strides=1, padding='same', activation='relu')(deconv6)\n","  deconv6 = BatchNormalization(momentum=0.8)(deconv6)\n","  deconv6 = Concatenate()([deconv6, conv1])\n","\n","  deconv7 = UpSampling2D(size=2)(deconv6)\n","  outputs = Conv2D(channels, kernel_size=4, strides=1, padding='same', activation='tanh')(deconv7)\n","\n","  return Model(inputs = inputs, outputs = outputs)\n","\n","\n","def Discriminator():\n","  img_A = Input(shape=img_shape)\n","  img_B = Input(shape=img_shape)\n","\n","  # Concatenate image and conditioning image by channels to produce input\n","  combined_imgs = Concatenate(axis=-1)([img_A, img_B])\n","  outputs = Conv2D(filters=64, kernel_size=4, strides=2, padding='same')(combined_imgs)\n","  outputs = LeakyReLU(alpha=0.2)(outputs)\n","\n","  outputs = Conv2D(filters=128, kernel_size=4, strides=2, padding='same')(outputs)\n","  outputs = LeakyReLU(alpha=0.2)(outputs)\n","  outputs = BatchNormalization(momentum=0.8)(outputs)\n","\n","  outputs = Conv2D(filters=256, kernel_size=4, strides=2, padding='same')(outputs)\n","  outputs = LeakyReLU(alpha=0.2)(outputs)\n","  outputs = BatchNormalization(momentum=0.8)(outputs)\n","\n","  outputs = Conv2D(filters=512, kernel_size=4, strides=2, padding='same')(outputs)\n","  outputs = LeakyReLU(alpha=0.2)(outputs)\n","  outputs = BatchNormalization(momentum=0.8)(outputs)\n","  \n","  outputs = Conv2D(1, kernel_size=4, strides=1, padding='same')(outputs)\n","\n","  return Model(inputs = [img_A, img_B], outputs = outputs)\n","\n","# Build and compile the discriminator\n","D = Discriminator()\n","D.compile(loss='mse', optimizer=optimizer, metrics=['accuracy'])\n","print(D.summary())\n","#-------------------------\n","# Construct Computational\n","#   Graph of Generator\n","#-------------------------\n","\n","# Build the generator\n","G = Generator()\n","print(G.summary())\n","\n","# Input images and their conditioning images\n","img_A = Input(shape=img_shape)\n","img_B = Input(shape=img_shape)\n","\n","# By conditioning on B generate a fake version of A\n","fake_A = G(img_B)\n","\n","# For the combined model we will only train the generator\n","D.trainable = False\n","\n","# Discriminators determines validity of translated images / condition pairs\n","valid = D([fake_A, img_B])\n","\n","combined = Model(inputs=[img_A, img_B], outputs=[valid, fake_A])\n","combined.compile(loss=['mse', 'mae'], loss_weights=[1, 100], optimizer=optimizer)\n"],"execution_count":22,"outputs":[{"output_type":"stream","text":["Model: \"model_7\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_11 (InputLayer)           (None, 256, 256, 3)  0                                            \n","__________________________________________________________________________________________________\n","input_12 (InputLayer)           (None, 256, 256, 3)  0                                            \n","__________________________________________________________________________________________________\n","concatenate_15 (Concatenate)    (None, 256, 256, 6)  0           input_11[0][0]                   \n","                                                                 input_12[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_39 (Conv2D)              (None, 128, 128, 64) 6208        concatenate_15[0][0]             \n","__________________________________________________________________________________________________\n","leaky_re_lu_23 (LeakyReLU)      (None, 128, 128, 64) 0           conv2d_39[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_40 (Conv2D)              (None, 64, 64, 128)  131200      leaky_re_lu_23[0][0]             \n","__________________________________________________________________________________________________\n","leaky_re_lu_24 (LeakyReLU)      (None, 64, 64, 128)  0           conv2d_40[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_31 (BatchNo (None, 64, 64, 128)  512         leaky_re_lu_24[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_41 (Conv2D)              (None, 32, 32, 256)  524544      batch_normalization_31[0][0]     \n","__________________________________________________________________________________________________\n","leaky_re_lu_25 (LeakyReLU)      (None, 32, 32, 256)  0           conv2d_41[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_32 (BatchNo (None, 32, 32, 256)  1024        leaky_re_lu_25[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_42 (Conv2D)              (None, 16, 16, 512)  2097664     batch_normalization_32[0][0]     \n","__________________________________________________________________________________________________\n","leaky_re_lu_26 (LeakyReLU)      (None, 16, 16, 512)  0           conv2d_42[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_33 (BatchNo (None, 16, 16, 512)  2048        leaky_re_lu_26[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_43 (Conv2D)              (None, 16, 16, 1)    8193        batch_normalization_33[0][0]     \n","==================================================================================================\n","Total params: 2,771,393\n","Trainable params: 2,769,601\n","Non-trainable params: 1,792\n","__________________________________________________________________________________________________\n","None\n","Model: \"model_8\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_13 (InputLayer)           (None, 256, 256, 3)  0                                            \n","__________________________________________________________________________________________________\n","conv2d_44 (Conv2D)              (None, 128, 128, 64) 3136        input_13[0][0]                   \n","__________________________________________________________________________________________________\n","leaky_re_lu_27 (LeakyReLU)      (None, 128, 128, 64) 0           conv2d_44[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_45 (Conv2D)              (None, 64, 64, 128)  131200      leaky_re_lu_27[0][0]             \n","__________________________________________________________________________________________________\n","leaky_re_lu_28 (LeakyReLU)      (None, 64, 64, 128)  0           conv2d_45[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_34 (BatchNo (None, 64, 64, 128)  512         leaky_re_lu_28[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_46 (Conv2D)              (None, 32, 32, 256)  524544      batch_normalization_34[0][0]     \n","__________________________________________________________________________________________________\n","leaky_re_lu_29 (LeakyReLU)      (None, 32, 32, 256)  0           conv2d_46[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_35 (BatchNo (None, 32, 32, 256)  1024        leaky_re_lu_29[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_47 (Conv2D)              (None, 16, 16, 512)  2097664     batch_normalization_35[0][0]     \n","__________________________________________________________________________________________________\n","leaky_re_lu_30 (LeakyReLU)      (None, 16, 16, 512)  0           conv2d_47[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_36 (BatchNo (None, 16, 16, 512)  2048        leaky_re_lu_30[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_48 (Conv2D)              (None, 8, 8, 512)    4194816     batch_normalization_36[0][0]     \n","__________________________________________________________________________________________________\n","leaky_re_lu_31 (LeakyReLU)      (None, 8, 8, 512)    0           conv2d_48[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_37 (BatchNo (None, 8, 8, 512)    2048        leaky_re_lu_31[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_49 (Conv2D)              (None, 4, 4, 512)    4194816     batch_normalization_37[0][0]     \n","__________________________________________________________________________________________________\n","leaky_re_lu_32 (LeakyReLU)      (None, 4, 4, 512)    0           conv2d_49[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_38 (BatchNo (None, 4, 4, 512)    2048        leaky_re_lu_32[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_50 (Conv2D)              (None, 2, 2, 512)    4194816     batch_normalization_38[0][0]     \n","__________________________________________________________________________________________________\n","leaky_re_lu_33 (LeakyReLU)      (None, 2, 2, 512)    0           conv2d_50[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_39 (BatchNo (None, 2, 2, 512)    2048        leaky_re_lu_33[0][0]             \n","__________________________________________________________________________________________________\n","up_sampling2d_15 (UpSampling2D) (None, 4, 4, 512)    0           batch_normalization_39[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_51 (Conv2D)              (None, 4, 4, 512)    4194816     up_sampling2d_15[0][0]           \n","__________________________________________________________________________________________________\n","batch_normalization_40 (BatchNo (None, 4, 4, 512)    2048        conv2d_51[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_16 (Concatenate)    (None, 4, 4, 1024)   0           batch_normalization_40[0][0]     \n","                                                                 batch_normalization_38[0][0]     \n","__________________________________________________________________________________________________\n","up_sampling2d_16 (UpSampling2D) (None, 8, 8, 1024)   0           concatenate_16[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_52 (Conv2D)              (None, 8, 8, 512)    8389120     up_sampling2d_16[0][0]           \n","__________________________________________________________________________________________________\n","batch_normalization_41 (BatchNo (None, 8, 8, 512)    2048        conv2d_52[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_17 (Concatenate)    (None, 8, 8, 1024)   0           batch_normalization_41[0][0]     \n","                                                                 batch_normalization_37[0][0]     \n","__________________________________________________________________________________________________\n","up_sampling2d_17 (UpSampling2D) (None, 16, 16, 1024) 0           concatenate_17[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_53 (Conv2D)              (None, 16, 16, 512)  8389120     up_sampling2d_17[0][0]           \n","__________________________________________________________________________________________________\n","batch_normalization_42 (BatchNo (None, 16, 16, 512)  2048        conv2d_53[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_18 (Concatenate)    (None, 16, 16, 1024) 0           batch_normalization_42[0][0]     \n","                                                                 batch_normalization_36[0][0]     \n","__________________________________________________________________________________________________\n","up_sampling2d_18 (UpSampling2D) (None, 32, 32, 1024) 0           concatenate_18[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_54 (Conv2D)              (None, 32, 32, 256)  4194560     up_sampling2d_18[0][0]           \n","__________________________________________________________________________________________________\n","batch_normalization_43 (BatchNo (None, 32, 32, 256)  1024        conv2d_54[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_19 (Concatenate)    (None, 32, 32, 512)  0           batch_normalization_43[0][0]     \n","                                                                 batch_normalization_35[0][0]     \n","__________________________________________________________________________________________________\n","up_sampling2d_19 (UpSampling2D) (None, 64, 64, 512)  0           concatenate_19[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_55 (Conv2D)              (None, 64, 64, 128)  1048704     up_sampling2d_19[0][0]           \n","__________________________________________________________________________________________________\n","batch_normalization_44 (BatchNo (None, 64, 64, 128)  512         conv2d_55[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_20 (Concatenate)    (None, 64, 64, 256)  0           batch_normalization_44[0][0]     \n","                                                                 batch_normalization_34[0][0]     \n","__________________________________________________________________________________________________\n","up_sampling2d_20 (UpSampling2D) (None, 128, 128, 256 0           concatenate_20[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_56 (Conv2D)              (None, 128, 128, 64) 262208      up_sampling2d_20[0][0]           \n","__________________________________________________________________________________________________\n","batch_normalization_45 (BatchNo (None, 128, 128, 64) 256         conv2d_56[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_21 (Concatenate)    (None, 128, 128, 128 0           batch_normalization_45[0][0]     \n","                                                                 leaky_re_lu_27[0][0]             \n","__________________________________________________________________________________________________\n","up_sampling2d_21 (UpSampling2D) (None, 256, 256, 128 0           concatenate_21[0][0]             \n","__________________________________________________________________________________________________\n","conv2d_57 (Conv2D)              (None, 256, 256, 3)  6147        up_sampling2d_21[0][0]           \n","==================================================================================================\n","Total params: 41,843,331\n","Trainable params: 41,834,499\n","Non-trainable params: 8,832\n","__________________________________________________________________________________________________\n","None\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","executionInfo":{"status":"error","timestamp":1582700532968,"user_tz":-300,"elapsed":6728975,"user":{"displayName":"ZEESHAN NISAR","photoUrl":"","userId":"05353617243036990298"}},"id":"BSkjGQqvCIht","outputId":"1562747c-6568-441c-ac17-14878d8153f0","colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1b3o1FSn7dme37oSXZVj0981mpDDqx8I6"}},"source":["import datetime\n","from PIL import Image\n","import sys\n","import matplotlib.pyplot as plt\n","\n","epochs = 200\n","batch_size = 1\n","resize = (256, 256)\n","\n","os.chdir('/content/drive/My Drive/GitHub Repositories/Generative Models Papers with Implementation in Keras')\n","baseDir = './Pix2PixGAN-Image-to-Image Translation with Conditional Adversarial Networks'\n","\n","\n","trainDir = os.path.join(baseDir, 'datasets', 'facades', 'train')\n","trainImages = os.listdir(trainDir)\n","batches = int(len(trainImages)/batch_size)\n","\n","validDir = os.path.join(baseDir, 'datasets', 'facades', 'test')\n","start_time = datetime.datetime.now()\n","\n","\n","outputDir = os.path.join(baseDir, 'outputs')\n","if not os.path.exists(outputDir):\n","    os.makedirs(outputDir)\n","    print('Output Directory Created to save Results')\n","  \n","\n","# Adversarial loss ground truths\n","valid = np.ones((batch_size,) + disc_patch)\n","fake = np.zeros((batch_size,) + disc_patch)\n","\n","def save_imgs(epoch):\n","    test_batch = 3\n","    r, c = 3, 3\n","    imgs_A = []\n","    imgs_B = []\n","    \n","    for i in range(test_batch):\n","        pickRandomImage = np.random.choice(os.listdir(validDir), size=batch_size)\n","        img = np.asarray(Image.open(os.path.join(validDir, ''.join(pickRandomImage))))\n","        h, w, _ = img.shape\n","        _w = int(w/2)\n","\n","        img_A, img_B = img[:, :_w, :], img[:, _w:, :]\n","        imgs_A.append(img_A)\n","        imgs_B.append(img_B)\n","    \n","    imgs_A = np.array(imgs_A)/127.5 - 1.\n","    imgs_B = np.array(imgs_B)/127.5 - 1.\n","\n","    fake_A = G.predict(imgs_B)\n","    gen_imgs = np.concatenate([imgs_B, fake_A, imgs_A])\n","\n","    # Rescale images 0 - 1\n","    gen_imgs = 0.5 * gen_imgs + 0.5\n","\n","    titles = ['Condition', 'Generated', 'Original']\n","    fig, axs = plt.subplots(r, c)\n","    cnt = 0\n","    for i in range(r):\n","        for j in range(c):\n","            axs[i,j].imshow(gen_imgs[cnt])\n","            axs[i, j].set_title(titles[i], pad=0.0)\n","            axs[i,j].axis('off')\n","            cnt += 1\n","    fig.savefig(outputDir+'/image_at_epoch_{:04d}.png'.format(epoch))\n","    plt.show()\n","    plt.close()\n","\n","for epoch in range(epochs):\n","    epoch+=1\n","    for batch in range(batches):\n","        batch+=1\n","        # ---------------------\n","        #  Train Discriminator\n","        # ---------------------\n","        imgs_A = []\n","        imgs_B = []\n","        pickRandomImage = np.random.choice(trainImages, size=batch_size)\n","        img = np.array(Image.open(os.path.join(trainDir, ''.join(pickRandomImage))))\n","        h, w, _= img.shape\n","        _w = int(w/2)\n","\n","        img_A, img_B = img[:, :_w, :], img[:, _w:, :]\n","        # If training => do random flip\n","        if np.random.random() < 0.5:\n","            img_A = np.fliplr(img_A)\n","            img_B = np.fliplr(img_B)\n","\n","        imgs_A.append(img_A)\n","        imgs_B.append(img_B)\n","\n","        imgs_A = np.array(imgs_A)/127.5 - 1.\n","        imgs_B = np.array(imgs_B)/127.5 - 1.\n","\n","        # Condition on B and generate a translated version\n","        fake_A = G.predict(imgs_B)\n","        # Train the discriminators (original images = real / generated = Fake)\n","        d_loss_real = D.train_on_batch([imgs_A, imgs_B], valid)\n","        d_loss_fake = D.train_on_batch([fake_A, imgs_B], fake)\n","        d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n","        \n","        # -----------------\n","        #  Train Generator\n","        # -----------------\n","        \n","        g_loss = combined.train_on_batch([imgs_A, imgs_B], [valid, imgs_A])\n","        elapsed_time = datetime.datetime.now() - start_time\n","        # Plot the training progress bar\n","        sys.stdout.write('\\r Epoch: {}/{} | Batch {}/{} | D-loss: {:.4f} | D-acc: {:.0f}% | G-loss: {:.3f} | time: {}'.format(epoch, epochs, batch, batches,\n","                                                                                               d_loss[0], 100*d_loss[1], g_loss[0], elapsed_time))\n","    # After each epoch save results\n","    save_imgs(epoch)"],"execution_count":23,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","metadata":{"id":"ik7vg6s8xQ3f","colab_type":"code","colab":{}},"source":["import imageio\n","import glob\n","images = []\n","for file_name in os.listdir(outputDir):\n","    if file_name.endswith('.png'):\n","        file_path = os.path.join(outputDir, file_name)\n","        images.append(imageio.imread(file_path))\n","imageio.mimsave(os.path.join(baseDir, 'Pix2Pix-training-outputs.gif'), images, fps = 3)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"gHh3S3xF0uJo","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}